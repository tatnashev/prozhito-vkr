{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b03b05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (3.5.2)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.8.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3eb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27f9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3c70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torch.optim import Adam\n",
    "from transformers import get_linear_schedule_with_warmup, AutoTokenizer, AutoModelForPreTraining\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb7dfd",
   "metadata": {},
   "source": [
    "## Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f30b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['B-LOC', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-FAC', 'I-FAC', 'B-CHAR', 'I-CHAR', 'O']\n",
    "\n",
    "bio2num = {\n",
    "    'B-LOC': 0, \n",
    "    'I-LOC': 1, \n",
    "    'B-ORG': 2, \n",
    "    'I-ORG': 3, \n",
    "    'B-PER': 4, \n",
    "    'I-PER': 5, \n",
    "    'B-FAC': 6, \n",
    "    'I-FAC': 7, \n",
    "    'B-CHAR': 8, \n",
    "    'I-CHAR': 9, \n",
    "    'O': 10 \n",
    "}\n",
    "\n",
    "MODEL_PATH = 'rubert-factru-finetuned/checkpoint-3950'\n",
    "OUTPUT_DIR = '.'\n",
    "res = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f210b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e218ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23bb34d",
   "metadata": {},
   "source": [
    "## Загружаем данные "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d7977",
   "metadata": {},
   "source": [
    "### FactRu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4633cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(labels): \n",
    "    nums = labels.split(', ')\n",
    "    nums[0] = nums[0][1:] \n",
    "    nums[-1] = nums[-1][:-1]\n",
    "\n",
    "    return list(map(int, nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a21631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bio(bio): \n",
    "    bios = bio.split(', ') \n",
    "    bios[0] = bios[0][1:] \n",
    "    bios[-1] = bios[-1][:-1] \n",
    "    for i, x in enumerate(bios): \n",
    "        bios[i] = x[1:-1]\n",
    "\n",
    "    return list(bios)\n",
    "\n",
    "def bio_to_num(bios): \n",
    "    ans = []\n",
    "    for bio in bios: \n",
    "        ans.append(bio2num[bio])\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4030638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>BIO</th>\n",
       "      <th>BIO_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Всё', 'это', 'время', 'я', 'просидел', 'в', ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Завод', ',', 'занимающий', 'лидирующие', 'по...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O,...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 0, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['\"', ',', '\"', 'Пока', 'все', 'дома', '\"', ',...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Мы', 'не', 'жалеем', 'никого', '.']</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[10, 10, 10, 10, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['«', 'Если', 'региону', 'необходимо', 'погаси...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  ['Всё', 'это', 'время', 'я', 'просидел', 'в', ...   \n",
       "1  ['Завод', ',', 'занимающий', 'лидирующие', 'по...   \n",
       "2  ['\"', ',', '\"', 'Пока', 'все', 'дома', '\"', ',...   \n",
       "3              ['Мы', 'не', 'жалеем', 'никого', '.']   \n",
       "4  ['«', 'Если', 'региону', 'необходимо', 'погаси...   \n",
       "\n",
       "                                                 BIO  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O,...   \n",
       "2         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                                    [O, O, O, O, O]   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                            BIO_nums  \n",
       "0  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...  \n",
       "1  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 0, 10...  \n",
       "2  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...  \n",
       "3                               [10, 10, 10, 10, 10]  \n",
       "4  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_factru = pd.read_csv('data/factru_test.csv')\n",
    "\n",
    "df_test_factru['BIO'] = df_test_factru['BIO'].apply(lambda x: preprocess_bio(x)) \n",
    "df_test_factru['BIO_nums'] = df_test_factru['BIO'].apply(lambda x: bio_to_num(x))\n",
    "df_test_factru.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f52218",
   "metadata": {},
   "source": [
    "### Размечено "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6032fef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tokens</th>\n",
       "      <th>BIO_str</th>\n",
       "      <th>BIO_nums</th>\n",
       "      <th>BIO_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>У меня большая симпатия к Лукьянину — человек ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&gt; Каким приговором , указом каким &gt; Ты здесь ,...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Подумал , что летом ребята куда затащили .</td>\n",
       "      <td>O O O O B-CHAR O O O</td>\n",
       "      <td>[10, 10, 10, 10, 8, 10, 10, 10]</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-CHAR', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Нашел потрясающие материалы о В . М . Брадисе ...</td>\n",
       "      <td>O O O O B-PER I-PER I-PER I-PER I-PER O O B-CH...</td>\n",
       "      <td>[10, 10, 10, 10, 4, 5, 5, 5, 5, 10, 10, 8, 8, ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Без даты . ]</td>\n",
       "      <td>O O O O</td>\n",
       "      <td>[10, 10, 10, 10]</td>\n",
       "      <td>['O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             tokens  \\\n",
       "0           0  У меня большая симпатия к Лукьянину — человек ...   \n",
       "1           2  > Каким приговором , указом каким > Ты здесь ,...   \n",
       "2           3         Подумал , что летом ребята куда затащили .   \n",
       "3           4  Нашел потрясающие материалы о В . М . Брадисе ...   \n",
       "4           5                                      [Без даты . ]   \n",
       "\n",
       "                                             BIO_str  \\\n",
       "0          O O O O O O O O O O O O O O O O O O O O O   \n",
       "1                  O O O O O O O O O O O O O O O O O   \n",
       "2                               O O O O B-CHAR O O O   \n",
       "3  O O O O B-PER I-PER I-PER I-PER I-PER O O B-CH...   \n",
       "4                                            O O O O   \n",
       "\n",
       "                                            BIO_nums  \\\n",
       "0  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "1  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "2                    [10, 10, 10, 10, 8, 10, 10, 10]   \n",
       "3  [10, 10, 10, 10, 4, 5, 5, 5, 5, 10, 10, 8, 8, ...   \n",
       "4                                   [10, 10, 10, 10]   \n",
       "\n",
       "                                            BIO_list  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2      ['O', 'O', 'O', 'O', 'B-CHAR', 'O', 'O', 'O']  \n",
       "3  ['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER'...  \n",
       "4                               ['O', 'O', 'O', 'O']  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_razmecheno = pd.read_csv('prozhito_data/df_train_prozhito.csv')\n",
    "df_test_razmecheno = pd.read_csv('prozhito_data/df_test_prozhito.csv')\n",
    "df_val_razmecheno = pd.read_csv('prozhito_data/df_val_prozhito.csv')\n",
    "\n",
    "df_train_razmecheno['BIO_nums'] = df_train_razmecheno['BIO_nums'].apply(lambda x: preprocess_labels(x)) \n",
    "df_test_razmecheno['BIO_nums'] = df_test_razmecheno['BIO_nums'].apply(lambda x: preprocess_labels(x)) \n",
    "df_val_razmecheno['BIO_nums'] = df_val_razmecheno['BIO_nums'].apply(lambda x: preprocess_labels(x)) \n",
    "\n",
    "df_train_razmecheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20ff24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_razmecheno['length'] = df_train_razmecheno['BIO_nums'].apply(lambda x: len(x))\n",
    "df_test_razmecheno['length'] = df_test_razmecheno['BIO_nums'].apply(lambda x: len(x))\n",
    "df_val_razmecheno['length'] = df_val_razmecheno['BIO_nums'].apply(lambda x: len(x))\n",
    "df_test_factru['length'] = df_test_factru['BIO_nums'].apply(lambda x: len(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895c360",
   "metadata": {},
   "source": [
    "## Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a95de432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    razmecheno_train: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 1258\n",
       "    })\n",
       "    razmecheno_test: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "    razmecheno_val: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 147\n",
       "    })\n",
       "    factru_test: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 907\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DatasetDict({\n",
    "    'razmecheno_train': Dataset.from_pandas(df_train_razmecheno[['tokens', 'BIO_nums', 'length']]),\n",
    "    'razmecheno_test': Dataset.from_pandas(df_test_razmecheno[['tokens', 'BIO_nums', 'length']]),\n",
    "    'razmecheno_val': Dataset.from_pandas(df_val_razmecheno[['tokens', 'BIO_nums', 'length']]), \n",
    "    'factru_test': Dataset.from_pandas(df_test_factru[['tokens', 'BIO_nums', 'length']])\n",
    "})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bdad674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_and_align(texts): \n",
    "    tokenized_input = tokenizer(texts['tokens'], truncation=True)\n",
    "    print(tokenized_input.keys())\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(texts['BIO_nums']): \n",
    "        word_ids = tokenized_input.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids: \n",
    "            if word_idx is None: \n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                if word_idx > len(label) - 1: \n",
    "                    label_ids.append(len(label_list) - 1)\n",
    "                else: \n",
    "                    label_ids.append(label[word_idx])\n",
    "            else: \n",
    "                if word_idx > len(label) - 1: \n",
    "                    label_ids.append(len(label_list) - 1)\n",
    "                else:\n",
    "                    label_ids.append(label[previous_word_idx])\n",
    "\n",
    "            previous_word_idx = word_idx\n",
    "            \n",
    "\n",
    "        label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_input['labels'] = labels \n",
    "    return tokenized_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d1d3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2935e275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc9d093b5dc4511a2277cdcac958771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1de0962be44f498c1d1fb7f81adb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f2a39041ac4beaacc2540a5e7556d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53831ec70ffa40d3b316cf1eab2aa178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = data.map(tokenizer_and_align, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns('tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778fde01",
   "metadata": {},
   "source": [
    "### Сортировка по длине батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "769f9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.sort('length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee015b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    razmecheno_train: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1258\n",
       "    })\n",
       "    razmecheno_test: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "    razmecheno_val: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 147\n",
       "    })\n",
       "    factru_test: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 907\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns('length')\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e60d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea1babd2",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4df9ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH, num_labels=len(bio2num))\n",
    "model.config.id2label = dict(enumerate(list(bio2num.keys())))\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7de71f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4517c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c24fb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e190513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_size): \n",
    "    model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH, num_labels=len(label_list))\n",
    "    model.config.id2label = dict(enumerate(label_list))\n",
    "    model.config.label2id = {v: k for k, v in model.config.id2label.items()}\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        \"rubert-factru-prozhito-finetuned\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=7,\n",
    "        weight_decay=1e-4,\n",
    "        report_to='none',\n",
    "        save_strategy='no', \n",
    "    )\n",
    "    if train_size < 1: \n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            train_dataset=tokenized_datasets['razmecheno_train'].train_test_split(train_size=train_size, seed=42)['train'],\n",
    "            eval_dataset=tokenized_datasets['razmecheno_val'],\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "    else: \n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            train_dataset=tokenized_datasets['razmecheno_train'],\n",
    "            eval_dataset=tokenized_datasets['razmecheno_val'],\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    import logging\n",
    "    from transformers.trainer import logger as noisy_logger\n",
    "    noisy_logger.setLevel(logging.WARNING)\n",
    "\n",
    "    trainer.train() \n",
    "\n",
    "    return trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd27b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, trainer, test_column): \n",
    "    predictions, labels, _ = trainer.predict(tokenized_datasets[test_column])\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "    # to dataframe \n",
    "    domains_ans = []\n",
    "    f1s = []\n",
    "    numbers = []\n",
    "    precs = []\n",
    "    recalls = []\n",
    "\n",
    "    for key in sorted(results.keys()):\n",
    "        if 'overall' not in key:\n",
    "            domains_ans.append(key)\n",
    "            f1s.append(round(results[key]['f1'], 4))\n",
    "            numbers.append(round(results[key]['number'], 4))\n",
    "            precs.append(round(results[key]['precision'], 4))\n",
    "            recalls.append(round(results[key]['recall'], 4))\n",
    "        else:\n",
    "            if key == 'overall_f1': \n",
    "                f1s.append(round(results[key], 4))\n",
    "            elif key == 'overall_precision': \n",
    "                precs.append(round(results[key], 4)) \n",
    "            elif key == 'overall_recall': \n",
    "                recalls.append(round(results[key], 4))\n",
    "\n",
    "    domains_ans.append('Overall')\n",
    "    numbers.append(sum(numbers))\n",
    "\n",
    "    to_add = pd.DataFrame({'tag': domains_ans,\n",
    "                'f1': f1s,\n",
    "                'precision': precs,\n",
    "                'recall': recalls,\n",
    "                'number of occurence': numbers})\n",
    "    \n",
    "    return to_add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89f8c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db2c661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:05, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.227661</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.216735</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.951546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208443</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.952469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.203501</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.952930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.202370</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.202954</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.955238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.203308</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.955238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:07, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.211864</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.952007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.185981</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.954776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.171737</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.955238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.165380</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.955699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.162174</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.955238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.161173</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.955238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.160695</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.954776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:08, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.209171</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.953853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.179317</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.956161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.159087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.956622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.958468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.146764</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.958468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144725</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.958468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144458</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.958929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:11, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.228093</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.944162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149664</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.953853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138738</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.314961</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138432</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.950623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.132168</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.132896</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.353741</td>\n",
       "      <td>0.953392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/112 00:18, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.952930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137929</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.956161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.127506</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.436090</td>\n",
       "      <td>0.962160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.135691</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.960775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144359</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.961237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144208</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.961698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.148366</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.961237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 00:25, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140139</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.964006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143711</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.954776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.135970</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.963544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142195</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>0.962621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170865</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.959852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.166841</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.961237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168582</td>\n",
       "      <td>0.450549</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.961698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='224' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [224/224 00:33, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.125517</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.963083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.963544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.121662</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.963083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138179</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.960775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.961698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.139774</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.965390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143242</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.965390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:40, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.131642</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.962621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.115416</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.482270</td>\n",
       "      <td>0.962621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.102364</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.962160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.130411</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.515723</td>\n",
       "      <td>0.961698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.133572</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.962160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137889</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.961698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141153</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.961237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [441/441 01:00, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.117530</td>\n",
       "      <td>0.440860</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.535948</td>\n",
       "      <td>0.962621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.094055</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.503311</td>\n",
       "      <td>0.963083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.117172</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.968620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.113463</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.128525</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.540881</td>\n",
       "      <td>0.967697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.136304</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.971389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.970928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='553' max='553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [553/553 01:17, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.956622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.965390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093419</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.964928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.099915</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>0.973696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.110625</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.971850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116153</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.975081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.624113</td>\n",
       "      <td>0.974158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='665' max='665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [665/665 01:31, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.490323</td>\n",
       "      <td>0.960314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.083930</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>0.972312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.079037</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.973696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.089353</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.971850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.088173</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.977388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.980618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.089429</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.978311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='826' max='826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [826/826 01:51, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.091078</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.960775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.070252</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>0.978311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.071655</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.979234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.076419</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.978772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.984310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.984772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.080693</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.982926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='994' max='994' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [994/994 02:14, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.078149</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.088283</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.978311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.070813</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.976927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.071326</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.982464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.086525</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.980618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.083635</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.982464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.085263</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.982464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-factru-finetuned/checkpoint-3950/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-factru-finetuned/checkpoint-3950\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-factru-finetuned/checkpoint-3950/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-factru-finetuned/checkpoint-3950.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1106' max='1106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1106/1106 02:29, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.084975</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.970928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.080574</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>0.977388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.073629</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.985695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.071361</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.985233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.067949</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.987540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.988002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.071469</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.989386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_size in train_sizes: \n",
    "    model = None\n",
    "    trainer = train(model, train_size) \n",
    "    factru_metrics = predict(model, trainer, 'factru_test')\n",
    "    razmecheno_metrics = predict(model, trainer, 'razmecheno_test') \n",
    "    \n",
    "    res[f'factru| train_size={train_size}'] = factru_metrics \n",
    "    res[f'razmecheno| train_size={train_size}'] = razmecheno_metrics \n",
    "    \n",
    "    del model \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94d92775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>number of occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">factru| train_size=0.01</th>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.5358</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.7527</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.5676</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>razmecheno| train_size=0.01</th>\n",
       "      <th>0</th>\n",
       "      <td>CHAR</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">razmecheno| train_size=1</th>\n",
       "      <th>1</th>\n",
       "      <td>FAC</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.8969</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tag      f1  precision  recall  \\\n",
       "factru| train_size=0.01     0      LOC  0.4986     0.6000  0.4265   \n",
       "                            1      ORG  0.4990     0.5358  0.4669   \n",
       "                            2      PER  0.6833     0.7527  0.6256   \n",
       "                            3  Overall  0.5676     0.6267  0.5187   \n",
       "razmecheno| train_size=0.01 0     CHAR  0.0000     0.0000  0.0000   \n",
       "...                                ...     ...        ...     ...   \n",
       "razmecheno| train_size=1    1      FAC  0.4000     0.3333  0.5000   \n",
       "                            2      LOC  0.9020     0.8519  0.9583   \n",
       "                            3      ORG  0.6667     1.0000  0.5000   \n",
       "                            4      PER  0.9315     0.9027  0.9623   \n",
       "                            5  Overall  0.8969     0.8788  0.9158   \n",
       "\n",
       "                               number of occurence  \n",
       "factru| train_size=0.01     0                  211  \n",
       "                            1                  529  \n",
       "                            2                  438  \n",
       "                            3                 1178  \n",
       "razmecheno| train_size=0.01 0                   56  \n",
       "...                                            ...  \n",
       "razmecheno| train_size=1    1                    2  \n",
       "                            2                   24  \n",
       "                            3                    2  \n",
       "                            4                  106  \n",
       "                            5                  190  \n",
       "\n",
       "[146 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.concat(res) \n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "297dd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fd271dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_excel('razmecheno_after_factru_epochs7.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3643999",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_razmecheno = [] \n",
    "f1_factru = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dffd1ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5676"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['factru| train_size=0.01']['f1'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b46aa92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(res.keys()): \n",
    "    if not i % 2:\n",
    "        f1_factru.append(res[k]['f1'].values[-1]) \n",
    "    else: \n",
    "        f1_razmecheno.append(res[k]['f1'].values[-1])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22412816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f1_factru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e385c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51586d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.array(train_sizes) * 100 \n",
    "train_sizes = train_sizes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4144e96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10, 7)) \n",
    "plt.xlabel('доля выборки, %')\n",
    "plt.ylabel('значение f1-меры')\n",
    "plt.title('FactRu -> Размечено (7 эпох)')\n",
    "plt.grid()\n",
    "plt.plot(train_sizes, f1_razmecheno, label='Размечено', marker='o') \n",
    "plt.plot(train_sizes, f1_factru, label='FactRu', marker='o') \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7752f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig('factru_razmecheno_7epochs.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee5749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
