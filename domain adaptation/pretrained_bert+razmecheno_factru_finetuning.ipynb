{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1faeb742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (3.5.2)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834adf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6aa87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268135fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torch.optim import Adam\n",
    "from transformers import get_linear_schedule_with_warmup, AutoTokenizer, AutoModelForPreTraining\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063c4df",
   "metadata": {},
   "source": [
    "## Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffefd25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['B-LOC', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-FAC', 'I-FAC', 'B-CHAR', 'I-CHAR', 'O']\n",
    "\n",
    "bio2num = {\n",
    "    'B-LOC': 0, \n",
    "    'I-LOC': 1, \n",
    "    'B-ORG': 2, \n",
    "    'I-ORG': 3, \n",
    "    'B-PER': 4, \n",
    "    'I-PER': 5, \n",
    "    'B-FAC': 6, \n",
    "    'I-FAC': 7, \n",
    "    'B-CHAR': 8, \n",
    "    'I-CHAR': 9, \n",
    "    'O': 10 \n",
    "}\n",
    "\n",
    "MODEL_PATH = 'rubert-razmecheno-finetuned/checkpoint-1580'\n",
    "OUTPUT_DIR = '.'\n",
    "res = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a4feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8cb9be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559fadb",
   "metadata": {},
   "source": [
    "## Загружаем данные "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c2dc4",
   "metadata": {},
   "source": [
    "### Размечено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd93bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(labels): \n",
    "    nums = labels.split(', ')\n",
    "    nums[0] = nums[0][1:] \n",
    "    nums[-1] = nums[-1][:-1]\n",
    "\n",
    "    return list(map(int, nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8027d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bio(bio): \n",
    "    bios = bio.split(', ') \n",
    "    bios[0] = bios[0][1:] \n",
    "    bios[-1] = bios[-1][:-1] \n",
    "    for i, x in enumerate(bios): \n",
    "        bios[i] = x[1:-1]\n",
    "\n",
    "    return list(bios)\n",
    "\n",
    "def bio_to_num(bios): \n",
    "    ans = []\n",
    "    for bio in bios: \n",
    "        ans.append(bio2num[bio])\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff422c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_razmecheno = pd.read_csv('prozhito_data/df_test_prozhito.csv')\n",
    "df_test_razmecheno['BIO_nums'] = df_test_razmecheno['BIO_nums'].apply(lambda x: preprocess_labels(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c29553",
   "metadata": {},
   "source": [
    "### FactRu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47716bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>BIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Я', 'голосовал', 'против', 'увольнения', 'Фе...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Белоруссия', ',', 'Казахстан', ',', 'как', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['В', 'то', 'же', 'время', 'канцлер', 'подчерк...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Спуск', 'корабля', 'с', 'орбиты', 'проходил'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Герой', 'Мураками', 'увлекается', 'западными...</td>\n",
       "      <td>['O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  ['Я', 'голосовал', 'против', 'увольнения', 'Фе...   \n",
       "1  ['Белоруссия', ',', 'Казахстан', ',', 'как', '...   \n",
       "2  ['В', 'то', 'же', 'время', 'канцлер', 'подчерк...   \n",
       "3  ['Спуск', 'корабля', 'с', 'орбиты', 'проходил'...   \n",
       "4  ['Герой', 'Мураками', 'увлекается', 'западными...   \n",
       "\n",
       "                                                 BIO  \n",
       "0  ['O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', '...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4  ['O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', '...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/factru_train.csv')\n",
    "df_test = pd.read_csv('data/factru_test.csv')\n",
    "df_val = pd.read_csv('data/factru_val.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8adb7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['BIO'] = df_train['BIO'].apply(lambda x: preprocess_bio(x))\n",
    "df_test['BIO'] = df_test['BIO'].apply(lambda x: preprocess_bio(x))\n",
    "df_val['BIO'] = df_val['BIO'].apply(lambda x: preprocess_bio(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d77f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['BIO_nums'] = df_train['BIO'].apply(lambda x: bio_to_num(x))\n",
    "df_val['BIO_nums'] = df_val['BIO'].apply(lambda x: bio_to_num(x))\n",
    "df_test['BIO_nums'] = df_test['BIO'].apply(lambda x: bio_to_num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b87a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_razmecheno['length'] = df_test_razmecheno['BIO_nums'].apply(lambda x: len(x))\n",
    "df_train['length'] = df_train['BIO_nums'].apply(lambda x: len(x))\n",
    "df_val['length'] = df_val['BIO_nums'].apply(lambda x: len(x))\n",
    "df_test['length'] = df_test['BIO_nums'].apply(lambda x: len(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797da13a",
   "metadata": {},
   "source": [
    "## Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22578fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    factru_train: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 3160\n",
       "    })\n",
       "    factru_test: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 907\n",
       "    })\n",
       "    factru_val: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 448\n",
       "    })\n",
       "    razmecheno_test: Dataset({\n",
       "        features: ['tokens', 'BIO_nums', 'length'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DatasetDict({\n",
    "    'factru_train': Dataset.from_pandas(df_train[['tokens', 'BIO_nums', 'length']]),\n",
    "    'factru_test': Dataset.from_pandas(df_test[['tokens', 'BIO_nums', 'length']]),\n",
    "    'factru_val': Dataset.from_pandas(df_val[['tokens', 'BIO_nums', 'length']]), \n",
    "    'razmecheno_test': Dataset.from_pandas(df_test_razmecheno[['tokens', 'BIO_nums', 'length']])\n",
    "})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe52956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_and_align(texts): \n",
    "    tokenized_input = tokenizer(texts['tokens'], truncation=True)\n",
    "    print(tokenized_input.keys())\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(texts['BIO_nums']): \n",
    "        word_ids = tokenized_input.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids: \n",
    "            if word_idx is None: \n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                if word_idx > len(label) - 1: \n",
    "                    label_ids.append(len(label_list) - 1)\n",
    "                else: \n",
    "                    label_ids.append(label[word_idx])\n",
    "            else: \n",
    "                if word_idx > len(label) - 1: \n",
    "                    label_ids.append(len(label_list) - 1)\n",
    "                else:\n",
    "                    label_ids.append(label[previous_word_idx])\n",
    "\n",
    "            previous_word_idx = word_idx\n",
    "            \n",
    "\n",
    "        label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_input['labels'] = labels \n",
    "    return tokenized_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7649274",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3151d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0268af66284fb69fcfb30adb799074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8195c8a15d4f42919676384795d73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e076dbe03b4fbbb7bb0a8b6bfcc612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef173d1e17a44cabef8b0e880a4d839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = data.map(tokenizer_and_align, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns('tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8a917",
   "metadata": {},
   "source": [
    "### Сортировка по длине батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab529259",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.sort('length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54db3980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    factru_train: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3160\n",
       "    })\n",
       "    factru_test: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 907\n",
       "    })\n",
       "    factru_val: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 448\n",
       "    })\n",
       "    razmecheno_test: Dataset({\n",
       "        features: ['BIO_nums', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns('length')\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43dc7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41cac6d7",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfad3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH, num_labels=len(bio2num))\n",
    "model.config.id2label = dict(enumerate(list(bio2num.keys())))\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00670874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcbf6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "859765a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b6b5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_size): \n",
    "    model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH, num_labels=len(label_list))\n",
    "    model.config.id2label = dict(enumerate(label_list))\n",
    "    model.config.label2id = {v: k for k, v in model.config.id2label.items()}\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        \"rubert-razmecheno_factru_finetuned\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=1e-4,\n",
    "        report_to='none',\n",
    "        save_strategy='no', \n",
    "    )\n",
    "    if train_size < 1: \n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            train_dataset=tokenized_datasets['factru_train'].train_test_split(train_size=train_size, seed=42)['train'],\n",
    "            eval_dataset=tokenized_datasets['factru_val'],\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "    else: \n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            args,\n",
    "            train_dataset=tokenized_datasets['factru_train'],\n",
    "            eval_dataset=tokenized_datasets['factru_val'],\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    import logging\n",
    "    from transformers.trainer import logger as noisy_logger\n",
    "    noisy_logger.setLevel(logging.WARNING)\n",
    "\n",
    "    trainer.train() \n",
    "\n",
    "    return trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dddc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, trainer, test_column): \n",
    "    predictions, labels, _ = trainer.predict(tokenized_datasets[test_column])\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "    # to dataframe \n",
    "    domains_ans = []\n",
    "    f1s = []\n",
    "    numbers = []\n",
    "    precs = []\n",
    "    recalls = []\n",
    "\n",
    "    for key in sorted(results.keys()):\n",
    "        if 'overall' not in key:\n",
    "            domains_ans.append(key)\n",
    "            f1s.append(round(results[key]['f1'], 4))\n",
    "            numbers.append(round(results[key]['number'], 4))\n",
    "            precs.append(round(results[key]['precision'], 4))\n",
    "            recalls.append(round(results[key]['recall'], 4))\n",
    "        else:\n",
    "            if key == 'overall_f1': \n",
    "                f1s.append(round(results[key], 4))\n",
    "            elif key == 'overall_precision': \n",
    "                precs.append(round(results[key], 4)) \n",
    "            elif key == 'overall_recall': \n",
    "                recalls.append(round(results[key], 4))\n",
    "\n",
    "    domains_ans.append('Overall')\n",
    "    numbers.append(sum(numbers))\n",
    "\n",
    "    to_add = pd.DataFrame({'tag': domains_ans,\n",
    "                'f1': f1s,\n",
    "                'precision': precs,\n",
    "                'recall': recalls,\n",
    "                'number of occurence': numbers})\n",
    "    \n",
    "    return to_add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "366b46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9723775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.173216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.166029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.150905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.146197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.157433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145091</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.974990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141657</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.974768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.136918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.127323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.125283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.133118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.117703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116045</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.975602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/180 00:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.124719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.111081</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.975546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106814</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.028419</td>\n",
       "      <td>0.052718</td>\n",
       "      <td>0.975824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [237/237 00:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.114362</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.024014</td>\n",
       "      <td>0.975546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.103782</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.975657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.100148</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.975407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='297' max='297' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [297/297 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.107806</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>0.975713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.098259</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>0.084142</td>\n",
       "      <td>0.976074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.056838</td>\n",
       "      <td>0.098009</td>\n",
       "      <td>0.975880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='474' max='474' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [474/474 01:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>0.975907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.088927</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.047957</td>\n",
       "      <td>0.085851</td>\n",
       "      <td>0.976519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.081348</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.072824</td>\n",
       "      <td>0.122024</td>\n",
       "      <td>0.976685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='594' max='594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [594/594 01:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.096673</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.058615</td>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.976157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>0.354545</td>\n",
       "      <td>0.069272</td>\n",
       "      <td>0.115899</td>\n",
       "      <td>0.976018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.077970</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.081705</td>\n",
       "      <td>0.130496</td>\n",
       "      <td>0.976463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='711' max='711' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [711/711 02:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.092252</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.063943</td>\n",
       "      <td>0.113744</td>\n",
       "      <td>0.976435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.078764</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.088810</td>\n",
       "      <td>0.145138</td>\n",
       "      <td>0.976269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.127886</td>\n",
       "      <td>0.187013</td>\n",
       "      <td>0.976324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='891' max='891' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [891/891 02:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.085962</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.063943</td>\n",
       "      <td>0.114833</td>\n",
       "      <td>0.976630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.075423</td>\n",
       "      <td>0.313364</td>\n",
       "      <td>0.120782</td>\n",
       "      <td>0.174359</td>\n",
       "      <td>0.976046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.067736</td>\n",
       "      <td>0.364532</td>\n",
       "      <td>0.131439</td>\n",
       "      <td>0.193211</td>\n",
       "      <td>0.977102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1068/1068 02:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.090277</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.090586</td>\n",
       "      <td>0.136182</td>\n",
       "      <td>0.974546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.067925</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.133215</td>\n",
       "      <td>0.192061</td>\n",
       "      <td>0.977102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.062006</td>\n",
       "      <td>0.360704</td>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.272124</td>\n",
       "      <td>0.977964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file rubert-razmecheno-finetuned/checkpoint-1580/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rubert-razmecheno-finetuned/checkpoint-1580\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-LOC\",\n",
      "    \"1\": \"I-LOC\",\n",
      "    \"2\": \"B-ORG\",\n",
      "    \"3\": \"I-ORG\",\n",
      "    \"4\": \"B-PER\",\n",
      "    \"5\": \"I-PER\",\n",
      "    \"6\": \"B-FAC\",\n",
      "    \"7\": \"I-FAC\",\n",
      "    \"8\": \"B-CHAR\",\n",
      "    \"9\": \"I-CHAR\",\n",
      "    \"10\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-CHAR\": 8,\n",
      "    \"B-FAC\": 6,\n",
      "    \"B-LOC\": 0,\n",
      "    \"B-ORG\": 2,\n",
      "    \"B-PER\": 4,\n",
      "    \"I-CHAR\": 9,\n",
      "    \"I-FAC\": 7,\n",
      "    \"I-LOC\": 1,\n",
      "    \"I-ORG\": 3,\n",
      "    \"I-PER\": 5,\n",
      "    \"O\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file rubert-razmecheno-finetuned/checkpoint-1580/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at rubert-razmecheno-finetuned/checkpoint-1580.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1185' max='1185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1185/1185 02:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.080269</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.976908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.067625</td>\n",
       "      <td>0.332117</td>\n",
       "      <td>0.161634</td>\n",
       "      <td>0.217443</td>\n",
       "      <td>0.976685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.414201</td>\n",
       "      <td>0.248668</td>\n",
       "      <td>0.310766</td>\n",
       "      <td>0.979853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_size in train_sizes: \n",
    "    model = None\n",
    "    trainer = train(model, train_size) \n",
    "    factru_metrics = predict(model, trainer, 'factru_test')\n",
    "    razmecheno_metrics = predict(model, trainer, 'razmecheno_test') \n",
    "    \n",
    "    res[f'razmecheno| train_size={train_size}'] = razmecheno_metrics \n",
    "    res[f'factru| train_size={train_size}'] = factru_metrics\n",
    "    \n",
    "    del model \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c07034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>number of occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">razmecheno| train_size=0.01</th>\n",
       "      <th>0</th>\n",
       "      <td>CHAR</td>\n",
       "      <td>0.8679</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAC</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>razmecheno| train_size=1</th>\n",
       "      <th>5</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">factru| train_size=1</th>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.2599</td>\n",
       "      <td>0.3576</td>\n",
       "      <td>0.2042</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.5015</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.3111</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.2436</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tag      f1  precision  recall  \\\n",
       "razmecheno| train_size=0.01 0     CHAR  0.8679     0.9200  0.8214   \n",
       "                            1      FAC  1.0000     1.0000  1.0000   \n",
       "                            2      LOC  0.9565     1.0000  0.9167   \n",
       "                            3      ORG  0.5000     0.5000  0.5000   \n",
       "                            4      PER  0.9182     0.8860  0.9528   \n",
       "...                                ...     ...        ...     ...   \n",
       "razmecheno| train_size=1    5  Overall  0.7339     0.7844  0.6895   \n",
       "factru| train_size=1        0      LOC  0.1134     0.3889  0.0664   \n",
       "                            1      ORG  0.2599     0.3576  0.2042   \n",
       "                            2      PER  0.4302     0.5015  0.3767   \n",
       "                            3  Overall  0.3111     0.4303  0.2436   \n",
       "\n",
       "                               number of occurence  \n",
       "razmecheno| train_size=0.01 0                   56  \n",
       "                            1                    2  \n",
       "                            2                   24  \n",
       "                            3                    2  \n",
       "                            4                  106  \n",
       "...                                            ...  \n",
       "razmecheno| train_size=1    5                  190  \n",
       "factru| train_size=1        0                  211  \n",
       "                            1                  529  \n",
       "                            2                  438  \n",
       "                            3                 1178  \n",
       "\n",
       "[143 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.concat(res) \n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc2cd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0923e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_excel('factru_after_razmecheno_epochs3_run1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72b69571",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_prozhito = [] \n",
    "f1_factru = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b524107e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['factru| train_size=0.01']['f1'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d37eac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(res.keys()): \n",
    "    if not i % 2:\n",
    "        f1_prozhito.append(res[k]['f1'].values[-1])  \n",
    "    else: \n",
    "        f1_factru.append(res[k]['f1'].values[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbce9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cb2debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.array(train_sizes) * 100 \n",
    "train_sizes = train_sizes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97f83452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10, 7)) \n",
    "plt.xlabel('доля выборки, %')\n",
    "plt.ylabel('значение f1-меры')\n",
    "plt.title('Размечено -> FactRu (3 эпохи)')\n",
    "plt.grid()\n",
    "plt.plot(train_sizes, f1_prozhito, label='Размечено', marker='o') \n",
    "plt.plot(train_sizes, f1_factru, label='FactRu', marker='o') \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41938a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig('razmecheno_factru_3epochs.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa6442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
